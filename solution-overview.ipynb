{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/edsa-recommender-system-predict/movies.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/imdb_data.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/genome_scores.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/sample_submission.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/tags.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/test.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/links.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/genome_tags.csv\n",
      "/kaggle/input/edsa-recommender-system-predict/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/test.csv')\n",
    "df_imdb = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/imdb_data.csv')\n",
    "df_tags = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/tags.csv')\n",
    "df_genome_tags = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/genome_tags.csv')\n",
    "df_genome_scores = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/genome_scores.csv')\n",
    "df_movies = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/movies.csv')\n",
    "df_links = pd.read_csv('/kaggle/input/edsa-recommender-system-predict/links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Hybrid Recommender System Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = df_movies[:20000]\n",
    "#movies =  movies.reset_index(drop=True)\n",
    "df_train = df_train.sample(frac=0.05)\n",
    "df_train =  df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9197  0.9262  0.9224  0.9257  0.9218  0.9231  0.0024  \n",
      "MAE (testset)     0.7089  0.7134  0.7096  0.7130  0.7103  0.7110  0.0018  \n",
      "Fit time          21.99   22.14   22.29   22.38   22.22   22.20   0.13    \n",
      "Test time         1.89    1.76    1.80    1.37    1.78    1.72    0.18    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.9197404 , 0.92620665, 0.92236781, 0.92566755, 0.92175672]),\n",
       " 'test_mae': array([0.7088666 , 0.7134349 , 0.70959516, 0.71302097, 0.71028207]),\n",
       " 'fit_time': (21.985774278640747,\n",
       "  22.144447088241577,\n",
       "  22.28642964363098,\n",
       "  22.381107091903687,\n",
       "  22.221081733703613),\n",
       " 'test_time': (1.8850903511047363,\n",
       "  1.762078046798706,\n",
       "  1.8049328327178955,\n",
       "  1.3741581439971924,\n",
       "  1.7828845977783203)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "df_movies.genres = df_movies.genres.str.replace('|', ' ')\n",
    "#movies = movies1# (movies1, ['genres'])  \n",
    "from surprise import Reader, Dataset, SVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df_movies['year'] = df_movies.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n",
    "#Removing the parentheses\n",
    "df_movies['year'] = df_movies.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n",
    "\n",
    "'''Applying the Cotent_Based Filtering'''\n",
    " #Applying Feature extraction \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "#matrix after applying the tfidf\n",
    "matrix=tfidf.fit_transform(df_movies['genres'])\n",
    "\n",
    "\n",
    "#Compute the cosine similarity of every genre\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim=cosine_similarity(matrix,matrix)\n",
    "\n",
    "'''Applying the Collaborative Filtering'''\n",
    "#Intialising the Reader which is used to parse the file containing the ratings \n",
    "reader=Reader()\n",
    "\n",
    "#Making the dataset containing the column as userid itemid ratings\n",
    "#the order is very specific and we have to follow the same order\n",
    "rating_dataset = Dataset.load_from_df(df_train[['userId','movieId','rating']],reader)\n",
    "#Using the split function to perform cross validation \n",
    "#rating_dataset.split(n_folds=6)\n",
    "#Intialising the SVD model and specifying the number of latent features\n",
    "#we can tune this parameters according to our requirement\n",
    "svd=SVD(n_factors=25)\n",
    "\n",
    "#making the dataset to train our model\n",
    "training = rating_dataset.build_full_trainset()\n",
    "#training our model\n",
    "svd.fit(training)\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(svd, rating_dataset, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_ratings=round(svd.predict(movie_id[id]).est,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9437112420141897"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import BaselineOnly\n",
    "from surprise import accuracy\n",
    "reader = Reader(rating_scale=(0.5,5.0))\n",
    "\n",
    "data = Dataset.load_from_df(df_train[['userId', 'movieId', 'rating']], reader)\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.5)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)\n",
    "# Log RMSE\n",
    "\n",
    "#trainset, testset = train_test_split(data, test_size=0.25)\n",
    "#predictions = algo.fit(trainset).test(testset)\n",
    "#accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
